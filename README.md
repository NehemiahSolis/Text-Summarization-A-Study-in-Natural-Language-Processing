# A Study in Natural Language Processing: Text Summarization

## Introduction

### Problem Statement

Today we live in an age of mass information, where it is easier than ever to access all sorts of information through online news articles, social media, and books. One of the problems we have in today’s age of “clickbait” headlines and catchy titles is that a good portion of readers don’t read the full article anymore. Or they go straight to SparkNotes instead of reading the book. Or maybe they just look at the star rating of a review instead of reading the full review for any nuance.

With that said, it is understandable that no one can read every article, book, or review they come across, as there is almost an overload of information through television, social media, and the internet.

### Solution

What this project seeks to solve is that problem: creating a simple text summarizer that can generate a good summary from a larger text. In this way, if one is pressed for time, or wants a good summary of information for any particle article, they can use the text summarization algorithm to handle all of the work that comes with creating a summary.

There are two types of text summarizations, as defined below:

**Extractive:**

This method selects a subset of words that seeks to retain the most important points of the larger text. It weighs the most important parts of the sentences in the text and then forms the summary based on those most important features. This is the method I will be working with for this model.

**Abstractive:**

This method is newer and less used than extractive. It selects words based on semantic understanding and attempts to produce material in new ways. It uses deep learning techniques to generate shorter texts that convey the most important parts of the original text.

### To review the project overview, visualizations, and results, please refer to the [Slide Presentation](). For the data, project code, and detailed NLP machine learning walkthrough, refer to the [Jupyter Notebook]().
